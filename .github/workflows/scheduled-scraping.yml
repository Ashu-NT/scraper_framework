name: Scheduled Scraping

on:
  schedule:
    # Run daily at 2 AM UTC (adjust timezone as needed)
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      job_config:
        description: 'Job configuration file to run'
        required: true
        default: 'configs/jobs/scheduled_example.yaml'
        type: string
      commit_results:
        description: 'Commit scraped results back to repository'
        required: false
        default: true
        type: boolean

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e .

    - name: Set up Google Sheets authentication (if needed)
      if: ${{ secrets.GOOGLE_SHEETS_CREDENTIALS != '' }}
      run: |
        echo "${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}" > service_account.json
        echo "GOOGLE_APPLICATION_CREDENTIALS=service_account.json" >> $GITHUB_ENV
      env:
        GOOGLE_SHEETS_CREDENTIALS: ${{ secrets.GOOGLE_SHEETS_CREDENTIALS }}

    - name: Run scheduled scraping job
      id: scrape
      run: |
        JOB_CONFIG="${{ github.event.inputs.job_config || 'configs/jobs/scheduled_example.yaml' }}"
        echo "Running scraping job: $JOB_CONFIG"

        # Check if job config exists
        if [ ! -f "$JOB_CONFIG" ]; then
          echo "Error: Job configuration file not found: $JOB_CONFIG"
          exit 1
        fi

        # Run the scraper
        python -m scraper_framework.main "$JOB_CONFIG"
      env:
        # Add any environment variables your scraper needs
        PYTHONPATH: ${{ github.workspace }}/src
      continue-on-error: true

    - name: Check for output changes
      id: check_changes
      run: |
        if [ -n "$(git status --porcelain)" ]; then
          echo "changes=true" >> $GITHUB_OUTPUT
        else
          echo "changes=false" >> $GITHUB_OUTPUT
        fi

    - name: Commit and push results
      if: steps.check_changes.outputs.changes == 'true' && steps.scrape.outcome == 'success' && (github.event.inputs.commit_results == 'true' || github.event_name == 'schedule')
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add .
        git commit -m "Update scraped data - $(date +'%Y-%m-%d %H:%M:%S UTC')"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Upload scraping logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: scraping-logs-${{ github.run_number }}
        path: |
          logs/
          *.log
        retention-days: 30